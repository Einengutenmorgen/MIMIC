{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7980c927",
   "metadata": {},
   "source": [
    "## Inspect Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff4b205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXPERIMENT SUMMARY ===\n",
      "Run ID: 20250708_125947\n",
      "Files checked: 161\n",
      "Files with run data: 3\n",
      "Users in this run: 3\n",
      "\n",
      "Per-user breakdown:\n",
      "  1.5196466670453228e+18: 1 rounds, 9 imitations\n",
      "  27995424.0: 1 rounds, 9 imitations\n",
      "  534023.0: 1 rounds, 9 imitations\n",
      "\n",
      "Quick stats:\n",
      "  Total rounds across all users: 3\n",
      "  Total imitations across all users: 27\n",
      "  Average rounds per user: 1.0\n",
      "  Average imitations per user: 9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def count_experiment_stats(users_dict_path, target_run_id=None):\n",
    "    \"\"\"\n",
    "    Counts basic stats for a given run_id across all user files.\n",
    "    \n",
    "    :param users_dict_path: Path to directory containing user .jsonl files\n",
    "    :param target_run_id: Optional run_id to analyze. If None, uses latest from first file\n",
    "    :return: Dictionary with counts and statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all jsonl files\n",
    "    user_files = [f for f in os.listdir(users_dict_path) if f.endswith('.jsonl')]\n",
    "    if not user_files:\n",
    "        print(f\"No .jsonl files found in {users_dict_path}\")\n",
    "        return None\n",
    "    \n",
    "    total_files = len(user_files)\n",
    "    files_with_run_data = 0\n",
    "    \n",
    "    # Get run_id if not provided\n",
    "    if target_run_id is None:\n",
    "        for uf in user_files:\n",
    "            try:\n",
    "                with open(os.path.join(users_dict_path, uf), 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                    if len(lines) > 2:\n",
    "                        runs_data = json.loads(lines[2].strip())\n",
    "                        if runs_data.get('runs'):\n",
    "                            target_run_id = runs_data['runs'][-1]['run_id']\n",
    "                            print(f\"Using run_id from {uf}: {target_run_id}\")\n",
    "                            break\n",
    "            except (json.JSONDecodeError, IndexError, FileNotFoundError):\n",
    "                continue\n",
    "    \n",
    "    if not target_run_id:\n",
    "        print(\"Could not determine run_id\")\n",
    "        return None\n",
    "    \n",
    "    # Count stats\n",
    "    user_stats = {}\n",
    "    \n",
    "    for user_file in user_files:\n",
    "        user_file_path = os.path.join(users_dict_path, user_file)\n",
    "        user_id = os.path.splitext(user_file)[0]\n",
    "        \n",
    "        try:\n",
    "            with open(user_file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            # Get actual user_id from file if available\n",
    "            if len(lines) > 0:\n",
    "                user_info = json.loads(lines[0].strip())\n",
    "                if 'user_id' in user_info:\n",
    "                    user_id = user_info['user_id']\n",
    "            \n",
    "            # Check if this file has run data for our target run\n",
    "            has_run_data = False\n",
    "            imitation_count = 0\n",
    "            \n",
    "            if len(lines) > 2:\n",
    "                try:\n",
    "                    runs_content = json.loads(lines[2].strip())\n",
    "                    target_run = next((r for r in runs_content.get('runs', []) \n",
    "                                     if r.get('run_id') == target_run_id), None)\n",
    "                    if target_run:\n",
    "                        has_run_data = True\n",
    "                        imitation_count = len(target_run.get('imitations', []))\n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "            \n",
    "            if has_run_data:\n",
    "                files_with_run_data += 1\n",
    "                \n",
    "                # Count rounds (evaluations)\n",
    "                round_count = 0\n",
    "                if len(lines) > 3:\n",
    "                    try:\n",
    "                        eval_content = json.loads(lines[3].strip())\n",
    "                        round_count = len([e for e in eval_content.get('evaluations', []) \n",
    "                                         if e.get('run_id') == target_run_id])\n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "                \n",
    "                user_stats[user_id] = {\n",
    "                    'rounds': round_count,\n",
    "                    'imitations': imitation_count\n",
    "                }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {user_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    results = {\n",
    "        'run_id': target_run_id,\n",
    "        'total_files_checked': total_files,\n",
    "        'files_with_run_data': files_with_run_data,\n",
    "        'total_users_in_run': len(user_stats),\n",
    "        'user_stats': user_stats\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_summary(results):\n",
    "    \"\"\"Print a nice summary of the results\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to display\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n=== EXPERIMENT SUMMARY ===\")\n",
    "    print(f\"Run ID: {results['run_id']}\")\n",
    "    print(f\"Files checked: {results['total_files_checked']}\")\n",
    "    print(f\"Files with run data: {results['files_with_run_data']}\")\n",
    "    print(f\"Users in this run: {results['total_users_in_run']}\")\n",
    "    \n",
    "    if results['user_stats']:\n",
    "        print(f\"\\nPer-user breakdown:\")\n",
    "        for user_id, stats in results['user_stats'].items():\n",
    "            print(f\"  {user_id}: {stats['rounds']} rounds, {stats['imitations']} imitations\")\n",
    "        \n",
    "        # Quick stats\n",
    "        rounds_list = [stats['rounds'] for stats in results['user_stats'].values()]\n",
    "        imitations_list = [stats['imitations'] for stats in results['user_stats'].values()]\n",
    "        \n",
    "        print(f\"\\nQuick stats:\")\n",
    "        print(f\"  Total rounds across all users: {sum(rounds_list)}\")\n",
    "        print(f\"  Total imitations across all users: {sum(imitations_list)}\")\n",
    "        if rounds_list:\n",
    "            print(f\"  Average rounds per user: {sum(rounds_list)/len(rounds_list):.1f}\")\n",
    "        if imitations_list:\n",
    "            print(f\"  Average imitations per user: {sum(imitations_list)/len(imitations_list):.1f}\")\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual path\n",
    "    path = r\"data\\filtered_users\"\n",
    "    \n",
    "    # Count stats for latest run (or specify run_id)\n",
    "    results = count_experiment_stats(path, '20250708_125947')\n",
    "    \n",
    "    if results:\n",
    "        print_summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb90bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXPERIMENT SUMMARY ===\n",
      "Run ID: 20250708_125947\n",
      "Files checked: 161\n",
      "Files with run data: 3\n",
      "Users in this run: 3\n",
      "\n",
      "Per-user breakdown:\n",
      "  1.5196466670453228e+18: 1 rounds, 9 imitations\n",
      "  27995424.0: 1 rounds, 9 imitations\n",
      "  534023.0: 1 rounds, 9 imitations\n",
      "\n",
      "Quick stats:\n",
      "  Total rounds across all users: 3\n",
      "  Total imitations across all users: 27\n",
      "  Average rounds per user: 1.0\n",
      "  Average imitations per user: 9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def count_experiment_stats_fixed(users_dict_path, target_run_id=None):\n",
    "    \"\"\"\n",
    "    Counts basic stats for a given run_id across all user files.\n",
    "    FIXED VERSION: Properly counts unique rounds instead of total evaluations\n",
    "    \n",
    "    :param users_dict_path: Path to directory containing user .jsonl files\n",
    "    :param target_run_id: Optional run_id to analyze. If None, uses latest from first file\n",
    "    :return: Dictionary with counts and statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all jsonl files\n",
    "    user_files = [f for f in os.listdir(users_dict_path) if f.endswith('.jsonl')]\n",
    "    if not user_files:\n",
    "        print(f\"No .jsonl files found in {users_dict_path}\")\n",
    "        return None\n",
    "    \n",
    "    total_files = len(user_files)\n",
    "    files_with_run_data = 0\n",
    "    \n",
    "    # Get run_id if not provided\n",
    "    if target_run_id is None:\n",
    "        for uf in user_files:\n",
    "            try:\n",
    "                with open(os.path.join(users_dict_path, uf), 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                    if len(lines) > 2:\n",
    "                        runs_data = json.loads(lines[2].strip())\n",
    "                        if runs_data.get('runs'):\n",
    "                            target_run_id = runs_data['runs'][-1]['run_id']\n",
    "                            print(f\"Using run_id from {uf}: {target_run_id}\")\n",
    "                            break\n",
    "            except (json.JSONDecodeError, IndexError, FileNotFoundError):\n",
    "                continue\n",
    "    \n",
    "    if not target_run_id:\n",
    "        print(\"Could not determine run_id\")\n",
    "        return None\n",
    "    \n",
    "    # Count stats\n",
    "    user_stats = {}\n",
    "    \n",
    "    for user_file in user_files:\n",
    "        user_file_path = os.path.join(users_dict_path, user_file)\n",
    "        user_id = os.path.splitext(user_file)[0]\n",
    "        \n",
    "        try:\n",
    "            with open(user_file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            # Get actual user_id from file if available\n",
    "            if len(lines) > 0:\n",
    "                user_info = json.loads(lines[0].strip())\n",
    "                if 'user_id' in user_info:\n",
    "                    user_id = user_info['user_id']\n",
    "            \n",
    "            # Check if this file has run data for our target run\n",
    "            has_run_data = False\n",
    "            imitation_count = 0\n",
    "            \n",
    "            if len(lines) > 2:\n",
    "                try:\n",
    "                    runs_content = json.loads(lines[2].strip())\n",
    "                    target_run = next((r for r in runs_content.get('runs', []) \n",
    "                                     if r.get('run_id') == target_run_id), None)\n",
    "                    if target_run:\n",
    "                        has_run_data = True\n",
    "                        imitation_count = len(target_run.get('imitations', []))\n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "            \n",
    "            if has_run_data:\n",
    "                files_with_run_data += 1\n",
    "                \n",
    "                # Count UNIQUE rounds (not total evaluations)\n",
    "                round_count = 0\n",
    "                total_evaluations = 0\n",
    "                \n",
    "                if len(lines) > 3:\n",
    "                    try:\n",
    "                        eval_content = json.loads(lines[3].strip())\n",
    "                        target_evaluations = [e for e in eval_content.get('evaluations', []) \n",
    "                                            if e.get('run_id') == target_run_id]\n",
    "                        \n",
    "                        total_evaluations = len(target_evaluations)\n",
    "                        \n",
    "                        # Count unique rounds\n",
    "                        unique_rounds = set()\n",
    "                        for eval_item in target_evaluations:\n",
    "                            if 'round' in eval_item:\n",
    "                                unique_rounds.add(eval_item['round'])\n",
    "                        \n",
    "                        round_count = len(unique_rounds)\n",
    "                        \n",
    "                        # If no 'round' field, assume each evaluation is a round\n",
    "                        if round_count == 0 and total_evaluations > 0:\n",
    "                            round_count = total_evaluations\n",
    "                            \n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "                \n",
    "                user_stats[user_id] = {\n",
    "                    'rounds': round_count,\n",
    "                    'imitations': imitation_count,\n",
    "                    'total_evaluations': total_evaluations  # Added for debugging\n",
    "                }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {user_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    results = {\n",
    "        'run_id': target_run_id,\n",
    "        'total_files_checked': total_files,\n",
    "        'files_with_run_data': files_with_run_data,\n",
    "        'total_users_in_run': len(user_stats),\n",
    "        'user_stats': user_stats\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_detailed_summary(results):\n",
    "    \"\"\"Print a detailed summary including evaluation counts\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to display\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n=== DETAILED EXPERIMENT SUMMARY ===\")\n",
    "    print(f\"Run ID: {results['run_id']}\")\n",
    "    print(f\"Files checked: {results['total_files_checked']}\")\n",
    "    print(f\"Files with run data: {results['files_with_run_data']}\")\n",
    "    print(f\"Users in this run: {results['total_users_in_run']}\")\n",
    "    \n",
    "    if results['user_stats']:\n",
    "        print(f\"\\nPer-user breakdown:\")\n",
    "        for user_id, stats in results['user_stats'].items():\n",
    "            print(f\"  {user_id}:\")\n",
    "            print(f\"    Unique rounds: {stats['rounds']}\")\n",
    "            print(f\"    Total evaluations: {stats['total_evaluations']}\")\n",
    "            print(f\"    Imitations: {stats['imitations']}\")\n",
    "        \n",
    "        # Quick stats\n",
    "        rounds_list = [stats['rounds'] for stats in results['user_stats'].values()]\n",
    "        imitations_list = [stats['imitations'] for stats in results['user_stats'].values()]\n",
    "        evaluations_list = [stats['total_evaluations'] for stats in results['user_stats'].values()]\n",
    "        \n",
    "        print(f\"\\nAggregate stats:\")\n",
    "        print(f\"  Total unique rounds: {sum(rounds_list)}\")\n",
    "        print(f\"  Total evaluations: {sum(evaluations_list)}\")\n",
    "        print(f\"  Total imitations: {sum(imitations_list)}\")\n",
    "        \n",
    "        if rounds_list:\n",
    "            print(f\"  Average rounds per user: {sum(rounds_list)/len(rounds_list):.1f}\")\n",
    "        if evaluations_list:\n",
    "            print(f\"  Average evaluations per user: {sum(evaluations_list)/len(evaluations_list):.1f}\")\n",
    "        if imitations_list:\n",
    "            print(f\"  Average imitations per user: {sum(imitations_list)/len(imitations_list):.1f}\")\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual path\n",
    "    path = r\"data\\filtered_users\"\n",
    "    \n",
    "    # Count stats for latest run (or specify run_id)\n",
    "    results = count_experiment_stats(path, '20250708_125947')\n",
    "    \n",
    "    if results:\n",
    "        print_summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ac9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
